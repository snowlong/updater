{"title":"アムダールの法則 - Wikipedia","body":"\t\t\n\t\t\n\t\t\n\t\t\t\n\t\t\t\n\nアムダールの法則\t\t\t\n\t\t\t\t出典: フリー百科事典『ウィキペディア（Wikipedia）』\t\t\t\t\n\t\t\t\t\t\t\t\tJump to navigation\n\t\t\t\tJump to search\n\t\t\t\t  複数のプロセッサを使って並列計算してプログラムの高速化を図る場合、そのプログラムの逐次的部分は、制限を受ける。例えば、プログラムの95%を並列化できたとしても、またどれだけプロセッサ数を増やしたとしても、図で示したように20倍以上には高速化しない。\nアムダールの法則（アムダールのほうそく、Amdahl's law）は、ある計算機システムとその対象とする計算についてのモデルにおいて、その計算機の並列度を上げた場合に、全体として期待できる全体の性能向上の程度を数式として表現したものである。コンピュータ・アーキテクトのジーン・アムダールが主張したものであり、Amdahl's argument（アムダールの主張）という呼称もある[1]。並列計算の分野において、複数のプロセッサを使ったときの理論上の性能向上の限界を予測するのによく使われる。\n複数のプロセッサを使い並列計算によってプログラムの高速化を図る場合、そのプログラムの中で逐次的に実行しなければならない部分の時間によって、高速化が制限される。例えば、1プロセッサでは20時間かかるプログラムがあり、その中の1時間かかる部分が並列化できないとする。したがって、19時間ぶん（95%）は並列化できるが、どれだけプロセッサを追加して並列化したとしても、そのプログラムの最小実行時間は1時間より短くならない。なぜなら、並列化できない部分に必ず1時間かかるため、図にも示したように、この場合の高速化は20倍までが限界だからである。\n\n目次\n\n1 詳細\n2 並列化\n3 収穫逓減の法則との関係\n4 アムダール本人の見解\n5 逐次的プログラムの高速化\n6 グスタフソンの法則との関係\n7 関連項目\n8 脚注\n9 参考文献\n10 外部リンク\n\n\n\n詳細[編集]\nアムダールの法則は、並列化しても問題の大きさが変化しないという前提と、問題には並列化できない部分があるという前提の上で、逐次的アルゴリズムとそれに対応したアルゴリズムの並列化実装によって期待できる高速化の関係をモデル化したものである。例えば、ある大きさの問題をあるアルゴリズムを並列化実装したもので実行した場合、問題の12%を並列化によって好きなように高速化できるとする（残り88%は並列化できない処理である）。アムダールの法則によれば、このときの並列化していない実装と比較した並列化版による高速化は最大でも \n  \n    \n      \n        \n          \n            1\n            \n              1\n              −\n              0.12\n            \n          \n        \n        =\n        1.136\n      \n    \n    {\\displaystyle {\\frac {1}{1-0.12}}=1.136}\n  \n 倍にしかならない。\nより技術的に解説すると、この法則は、ある計算のうち高速化によって影響を受ける部分の割合 P とその性能向上率 S から、全体として達成可能な性能向上率を求めるものである。例えば、ある改良が計算全体の 30% に影響する場合、P は 0.3 である。また、その部分が2倍に高速化されるなら S は 2 である。アムダールの法則によれば、全体としての性能向上は次の式で表される。\n\n\n  \n    \n      \n        \n          \n            1\n            \n              (\n              1\n              −\n              P\n              )\n              +\n              \n                \n                  P\n                  S\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {1}{(1-P)+{\\frac {P}{S}}}}}\n  \n.\n従来の計算時間を 1 とする。改良されたプログラムの計算時間は、改良と関係しない部分の計算時間（1 − P）と改良された部分の計算時間（P/S）の合計となる。全体の性能向上率は、従来の計算時間を改良されたプログラムの計算時間で割ったものであり、上の式はそれを表している。\nもう少し複雑な例を挙げる。あるタスクが4つの部分に分割されるとする。各部のタスク実行時間に占める割合は P1 = 0.11 (11%)、P2 = 0.18 (18%)、P3 = 0.23 (23%)、P4 = 0.48 (48%) で、全部を合計すると 100% になる。そこで、各部分に独自の改良を施す。P1 は改良しないので S1 = 1 (100%)、P2 は5倍に性能向上したので S2 = 5 (500%)、同様に S3 = 20 (2000%)、S4 = 1.6 (160%) とする。改良されたタスクの実行時間は \n  \n    \n      \n        \n          \n            \n              P\n              1\n            \n            \n              S\n              1\n            \n          \n        \n        +\n        \n          \n            \n              P\n              2\n            \n            \n              S\n              2\n            \n          \n        \n        +\n        \n          \n            \n              P\n              3\n            \n            \n              S\n              3\n            \n          \n        \n        +\n        \n          \n            \n              P\n              4\n            \n            \n              S\n              4\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {P1}{S1}}+{\\frac {P2}{S2}}+{\\frac {P3}{S3}}+{\\frac {P4}{S4}}}\n  \n であるから、これに代入すると \n\n\n  \n    \n      \n        \n          \n            \n              0.11\n              1\n            \n          \n          +\n          \n            \n              0.18\n              5\n            \n          \n          +\n          \n            \n              0.23\n              20\n            \n          \n          +\n          \n            \n              0.48\n              1.6\n            \n          \n        \n        =\n        0.4575\n      \n    \n    {\\displaystyle {{\\frac {0.11}{1}}+{\\frac {0.18}{5}}+{\\frac {0.23}{20}}+{\\frac {0.48}{1.6}}}=0.4575}\n  \n\nとなり、オリジナルの半分弱の時間ということがわかる。従って、性能向上率は \n  \n    \n      \n        \n          \n            1\n            0.4575\n          \n        \n        =\n        2.186\n      \n    \n    {\\displaystyle {\\frac {1}{0.4575}}=2.186}\n  \n と約2倍以上になる。注意すべきは、20倍とか5倍といった改良を施しても、システム全体としてはあまり効果が出ない点である。これは、P4 が元々実行時間の約半分を占めていて、S4 が 1.6 という点と P1 が全く改良されていない点が影響している。\n\n並列化[編集]\n  並列コンピューティングで複数のプロセッサを使って性能向上を図る場合、対象プログラムの並列化できない部分の割合に大きく左右される。例えば、プログラムの半分(0.5)が並列実行できない場合、理論上の性能向上限界は 2 となる（1/(0.5+(1-0.5)/N) で N を極限まで大きくした場合）。\nプログラムの並列化できる部分の実行時間の割合を P としたとき、並列化不可能な部分は (1 − P)であり、N個のプロセッサを使ったときの全体の性能向上率は次の式で表される。\n\n\n  \n    \n      \n        S\n        (\n        N\n        )\n        =\n        \n          \n            1\n            \n              (\n              1\n              −\n              P\n              )\n              +\n              \n                \n                  P\n                  N\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle S(N)={\\frac {1}{(1-P)+{\\frac {P}{N}}}}}\n  \n\nN が無限大に近づく極限では、性能向上率は 1 / (1 − P) となる。実際、(1 − P) の並列化不可能な成分がどれほど小さくとも N が大きくなれば価格性能比は急激に低下していく。\n例として、P が90%ならば (1 − P) は 10% となり、N をどれだけ大きくしても性能向上は1プロセッサの10倍までで頭打ちとなる。このため、並列計算が有効であるのは、プロセッサ数が少ない場合か、適応領域の問題の P の値が極めて大きい場合（embarrassingly parallel 問題と呼ぶ）に限られる。並列計算のプログラミング技法の多くは、(1 – P) を可能な限り小さくするためのものである。\n特定のプロセッサ数 (NP) での実測高速化係数 (SU) すなわち1プロセッサの何倍の性能かという値を使えば、P すなわち並列化可能部分の割合は次のように推定できる。\n\n\n  \n    \n      \n        \n          P\n          \n            estimated\n          \n        \n        =\n        \n          \n            \n              \n                \n                  1\n                  \n                    S\n                    U\n                  \n                \n              \n              −\n              1\n            \n            \n              \n                \n                  1\n                  \n                    N\n                    P\n                  \n                \n              \n              −\n              1\n            \n          \n        \n      \n    \n    {\\displaystyle P_{\\text{estimated}}={\\frac {{\\frac {1}{SU}}-1}{{\\frac {1}{NP}}-1}}}\n  \n\nこのように推定した P をアムダールの法則の式に適用すれば、異なるプロセッサ数での高速化の度合いが推定できる。\n\n\n80%の性能を出すのに必要な並列度\n\n\nプロセッサ数(N)\n\n順次実行部分の実行時間の割合\n\n\n2\n25%\n\n\n4\n8.3%\n\n\n6\n5.0%\n\n\n8\n3.6%\n\n\n12\n2.3%\n\n\n16\n1.7%\n\n\n32\n0.81%\n\n\n64\n0.40%\n\n\n256\n0.10%\n\n\n1024\n0.024%\n\n\n4096\n0.0061%\n\n\n65536\n0.00038%\n\nこれは 0.25 / (N - 1) で計算できる。\n\n収穫逓減の法則との関係[編集]\nアムダールの法則は収穫逓減の法則と組み合わせて述べられることが多いが、アムダールの法則を適用した特殊な例のみが「収穫逓減の法則」を示す。最初から（性能向上の観点で）最適な実装をしていく場合、改良に対して得られる性能向上は単調減少していく。しかし最適でない改良なら、さらなる改良を施すことで新たな性能向上が得られる場合もある。一般にシステムの改良は困難を伴う場合や時間がかかる場合があり、必ずしも常に最善の改良を行えるわけではない。\nプロセッサを追加するとそれに対応して並列化して動作するプログラムがあるとする。そのようなプログラムで解くべき問題の大きさが固定の場合に、プロセッサを追加して性能向上を図ろうとしたとき、アムダールの法則は収穫逓減の法則と同じことを表す。プロセッサを追加する度に、それによって得られる性能向上の度合いは減っていく。プロセッサを倍増させたときの性能向上比率は減少していき、最終的には \n  \n    \n      \n        \n          1\n          \n            /\n          \n          (\n          1\n          \n          −\n          \n          P\n          )\n        \n      \n    \n    {\\displaystyle \\scriptstyle 1/(1\\,-\\,P)}\n  \n へと近づいていく。\nここでは、メモリ帯域幅やI/O帯域幅といったボトルネックの可能性を考慮していない。それらがプロセッサ数に比例して拡大しないなら、収穫逓減の傾向がさらに強まることになる。\n\nアムダール本人の見解[編集]\n結局のところ（並列化のオーバヘッドといったものを全て無視できるとしても）、解きたい問題が必要とする計算のうち、どれだけが並列化可能か、という点が支配的であり、アムダール本人は並列化による高性能化に悲観的であったと言われる[2]。高性能計算の識者の間でも以前は見解が分かれており、ゴードン・ベル賞はこの問題へのチャレンジとして当初は設定された[3]。\n\n逐次的プログラムの高速化[編集]\n  タスクが独立した二つの部分 A と B から構成されている。B は計算時間の約25%を占めている。がんばって B を改良して5倍の性能にしても、全体としての性能向上は少しでしかない。逆に A を2倍の性能に改良した方が全体性能はより向上する。\nある逐次的プログラムを改良したときの最大高速化係数は、そのプログラムの一部を \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n 倍に高速化した場合、次の不等式で表される。\n\n\n  \n    \n      \n        \n          maximum speedup \n        \n        ≤\n        \n          \n            p\n            \n              1\n              +\n              f\n              ⋅\n              (\n              p\n              −\n              1\n              )\n            \n          \n        \n      \n    \n    {\\displaystyle {\\text{maximum speedup }}\\leq {\\frac {p}{1+f\\cdot (p-1)}}}\n  \n\nここで \n  \n    \n      \n        \n          f\n        \n      \n    \n    {\\displaystyle \\scriptstyle f}\n  \n (\n  \n    \n      \n        \n          0\n          \n          <\n          \n          f\n          \n          <\n          \n          1\n        \n      \n    \n    {\\displaystyle \\scriptstyle 0\\;<\\;f\\;<\\;1}\n  \n) は、改良した部分の（改良以前の）所要時間の割合である。例えば（右図参照）、\n\nB を5倍に高速化した場合 (\n  \n    \n      \n        \n          p\n          \n          =\n          \n          5\n        \n      \n    \n    {\\displaystyle \\scriptstyle p\\;=\\;5}\n  \n)、\n  \n    \n      \n        \n          \n            t\n            \n              A\n            \n          \n          \n          =\n          \n          3\n        \n      \n    \n    {\\displaystyle \\scriptstyle t_{A}\\;=\\;3}\n  \n、\n  \n    \n      \n        \n          \n            t\n            \n              B\n            \n          \n          \n          =\n          \n          1\n        \n      \n    \n    {\\displaystyle \\scriptstyle t_{B}\\;=\\;1}\n  \n、\n  \n    \n      \n        \n          f\n          \n          =\n          \n          \n            t\n            \n              A\n            \n          \n          \n            /\n          \n          (\n          \n            t\n            \n              A\n            \n          \n          \n          +\n          \n          \n            t\n            \n              B\n            \n          \n          )\n          \n          =\n          \n          0.75\n        \n      \n    \n    {\\displaystyle \\scriptstyle f\\;=\\;t_{A}/(t_{A}\\,+\\,t_{B})\\;=\\;0.75}\n  \n とすると、\n\n  \n    \n      \n        \n          maximum speedup \n        \n        ≤\n        \n          \n            5\n            \n              1\n              +\n              0.75\n              ⋅\n              (\n              5\n              −\n              1\n              )\n            \n          \n        \n        =\n        1.25\n      \n    \n    {\\displaystyle {\\text{maximum speedup }}\\leq {\\frac {5}{1+0.75\\cdot (5-1)}}=1.25}\n  \n\nA を2倍に高速化した場合 (\n  \n    \n      \n        \n          p\n          \n          =\n          \n          2\n        \n      \n    \n    {\\displaystyle \\scriptstyle p\\;=\\;2}\n  \n)、\n  \n    \n      \n        \n          \n            t\n            \n              B\n            \n          \n          \n          =\n          \n          1\n        \n      \n    \n    {\\displaystyle \\scriptstyle t_{B}\\;=\\;1}\n  \n、\n  \n    \n      \n        \n          \n            t\n            \n              A\n            \n          \n          \n          =\n          \n          3\n        \n      \n    \n    {\\displaystyle \\scriptstyle t_{A}\\;=\\;3}\n  \n、\n  \n    \n      \n        \n          f\n          \n          =\n          \n          \n            t\n            \n              B\n            \n          \n          \n            /\n          \n          (\n          \n            t\n            \n              A\n            \n          \n          \n          +\n          \n          \n            t\n            \n              B\n            \n          \n          )\n          \n          =\n          \n          0.25\n        \n      \n    \n    {\\displaystyle \\scriptstyle f\\;=\\;t_{B}/(t_{A}\\,+\\,t_{B})\\;=\\;0.25}\n  \n とすると、\n\n  \n    \n      \n        \n          maximum speedup \n        \n        ≤\n        \n          \n            2\n            \n              1\n              +\n              0.25\n              ⋅\n              (\n              2\n              −\n              1\n              )\n            \n          \n        \n        =\n        1.60\n      \n    \n    {\\displaystyle {\\text{maximum speedup }}\\leq {\\frac {2}{1+0.25\\cdot (2-1)}}=1.60}\n  \n\nとなる。したがって、Aを2倍に高速化した方がBを5倍に高速化するよりもよい結果となる。性能向上をパーセントで表す場合、次のように計算できる。\n\n\n  \n    \n      \n        \n          percentage improvement\n        \n        =\n        \n          (\n          \n            1\n            −\n            \n              \n                1\n                speedup factor\n              \n            \n          \n          )\n        \n        ⋅\n        100\n      \n    \n    {\\displaystyle {\\text{percentage improvement}}=\\left(1-{\\frac {1}{\\text{speedup factor}}}\\right)\\cdot 100}\n  \n\nAを2倍に高速化すると、プログラム全体は1.6倍に高速化し、オリジナルから37.5%の性能向上となる。\nしかし、Bを5倍に高速化しても、全体としては1.25倍の高速化でしかなく、20%しか性能向上しない。\nグスタフソンの法則との関係[編集]\n1988年、ジョン・グスタフソン（英語版）はグスタフソンの法則と呼ばれることを指摘した。すなわち、人々が関心を持っているのは、アムダールの法則で示されるように、既に解かれた問題をより高速に解くことではなく、より大きな問題を（可能な限り正確な近似で）それなりの時間内に解くことだ、という点である。並列化できない部分が固定あるいは、問題の大きさの増大に対して非常にゆっくり増大する場合（例えば、O(log n)）、解ける問題の大きさはプロセッサの追加に比例して増大していく。\n\n関連項目[編集]\nアムダール社\nジーン・アムダール\n性能解析\nクリティカルパス法\nブルックスの法則\nムーアの法則\n90対90の法則\nグスタフソンの法則\nニールギュンターの法則\n脚注[編集]\n\n\n^ Rodgers 1985, p. 226\n\n^ 富士通と共同開発したアムダールコンピュータでも、アムダール側のモデルはマルチプロセッサとしなかった（ http://homepage2.nifty.com/Miwa/6_F230-60/6_7(4).html ）\n\n^ https://twitter.com/ProfMatsuoka/status/536447955352289280\n\n\n参考文献[編集]\nAmdahl, Gene (1967年). “Validity of the Single Processor Approach to Achieving Large-Scale Computing Capabilities” (PDF). AFIPS Conference Proceedings (30):  483–485. http://www-inst.eecs.berkeley.edu/~n252/paper/Amdahl.pdf. \nRodgers, David P. (1985年6月). “Improvements in multiprocessor system design”. ACM SIGARCH Computer Architecture News archive (New York, NY, USA: ACM) 13 (3):  225–231. doi:10.1145/327070.327215. ISSN 0163-5964. http://portal.acm.org/citation.cfm?id=327215. \n\n\n外部リンク[編集]\n\n\n\nウィキメディア・コモンズには、アムダールの法則に関連するカテゴリがあります。\nCases where Amdahl's law is inapplicable\nOral history interview with Gene M. Amdahl Charles Babbage Institute, University of Minnesota.\nReevaluating Amdahl's Law\nReevaluating Amdahl's Law and Gustafson's Law\nA simple interactive Amdahl's Law calculator\n\"Amdahl's Law\" by Joel F. Klein, Wolfram Demonstrations Project, 2007.\nAmdahl's Law in the Multicore Era\nAmdahl's Law explanation\nBlog Post: \"What the $#@! is Parallelism, Anyhow?\"\nAmdahl's Law applied to OS system calls on multicore CPU\n表話編歴並列計算総論\nクラウドコンピューティング\nグリッド・コンピューティング\n高性能計算\nコンピュータ・クラスター\n分散コンピューティング並列レベル\nタスク\nデータ\nビット\n命令スレッド\nスーパースレッディング（英語版）\nハイパースレッディング理論\nアムダールの法則\nグスタフソンの法則\nコスト効率性（英語版）\nKarp-Flatt metric（英語版）\nParallel slowdown（英語版）\nSpeedup（英語版）要素\nスレッド\nファイバー\nプロセス\nPRAM\nInstruction window（英語版）調整\nキャッシュコヒーレンシ\n同期\nバリア\nマルチスレッディング\nマルチプロセッシング\nメモリコヒーレンス\nCache invalidation（英語版）\nApplication checkpointing（英語版）プログラミング\nスレッド (コンピュータ)\n並列プログラミングモデル\nImplicit parallelism（英語版）\nExplicit parallelism（英語版）\n並行性\nフリンの分類\nSISD\nSIMD\nMISD\nMIMD\nSPMD（英語版）\nLock-freeとWait-freeアルゴリズムハードウェア\nスーパーコンピュータ\nスーパースカラー\nベクトル計算機\nマルチプロセッシング\n対称型\n非対称型\nマルチコア\nメモリ\nNUMA\nen:COMA\nen:分散型\n共有型\n分散共有型\nSMT\nMPP\nBeowulfAPI\nAteji PX（英語版）\nBoostスレッド\nC++ AMP\nCharm++（英語版）\nCilk（英語版）\nCoarray Fortran（英語版）\nCUDA\nDryad（英語版）\nGlobal Arrays（英語版）\nIntel Cilk Plus（英語版）\nIntel Threading Building Blocks\nMPI\nOpenACC（英語版）\nOpenCL\nOpenHMPP（英語版）\nOpenMP\nPVM\nPOSIXスレッド\nUPC問題\nen:Embarrassingly parallel\nen:Grand Challenge\nen:Software lockout\n並行計算\nカテゴリ:並行計算\nカテゴリ:並列コンピューティング\n\n\n\n\n\n<img src=\"//ja.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1\" alt=\"\" title=\"\" width=\"1\" height=\"1\" style=\"border: none; position: absolute;\" />\t\t\t\t\t\n\t\t\t\t\t\t「https://ja.wikipedia.org/w/index.php?title=アムダールの法則&oldid=67406945」から取得\t\t\t\t\t\n\t\t\t\tカテゴリ: コンピュータアーキテクチャコンピュータに関する法則並列コンピューティングエポニム\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\n\t\t\n\t\t\t案内メニュー\n\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t個人用ツール\n\t\t\t\t\t\t\n\t\t\t\t\t\t\tログインしていませんトーク投稿記録アカウント作成ログイン\t\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t名前空間\n\t\t\t\t\t\t\n\t\t\t\t\t\t\tページノート\t\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t変種\n\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t表示\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t閲覧編集履歴表示\t\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\tその他\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t検索\n\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\n\t\t\t\n\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t案内\n\t\t\t\n\t\t\t\t\t\t\t\t\n\t\t\t\t\tメインページコミュニティ・ポータル最近の出来事新しいページ最近の更新おまかせ表示練習用ページアップロード (ウィキメディア・コモンズ)\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\n\t\t\t\n\t\t\tヘルプ\n\t\t\t\n\t\t\t\t\t\t\t\t\n\t\t\t\t\tヘルプ井戸端お知らせバグの報告寄付ウィキペディアに関するお問い合わせ\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\n\t\t\t\n\t\t\tツール\n\t\t\t\n\t\t\t\t\t\t\t\t\n\t\t\t\t\tリンク元関連ページの更新状況ファイルをアップロード特別ページこの版への固定リンクページ情報ウィキデータ項目このページを引用\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\n\t\t\t\n\t\t\t印刷/書き出し\n\t\t\t\n\t\t\t\t\t\t\t\t\n\t\t\t\t\tブックの新規作成PDF 形式でダウンロード印刷用バージョン\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\n\t\t\t\n\t\t\t他のプロジェクト\n\t\t\t\n\t\t\t\t\t\t\t\t\n\t\t\t\t\tコモンズ\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\n\t\t\t\n\t\t\t他言語版\n\t\t\t\n\t\t\t\t\t\t\t\t\n\t\t\t\t\tالعربيةCatalàČeštinaDeutschEnglishEspañolEestiفارسیFrançaisעבריתHrvatskiBahasa IndonesiaItaliano한국어МакедонскиPolskiPortuguêsRomânăРусскийSlovenčinaСрпски / srpskiTürkçeУкраїнськаTiếng Việt中文\t\t\t\t\n\t\t\t\tリンクを編集\t\t\t\n\t\t\n\t\t\t\t\n\t\t\n\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t 最終更新 2018年2月16日 (金) 17:11 （日時は個人設定で未設定ならばUTC）。\n\t\t\t\t\t\t\t\tテキストはクリエイティブ・コモンズ 表示-継承ライセンスの下で利用可能です。追加の条件が適用される場合があります。詳細は利用規約を参照してください。\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\tプライバシー・ポリシー\n\t\t\t\t\t\t\t\tウィキペディアについて\n\t\t\t\t\t\t\t\t免責事項\n\t\t\t\t\t\t\t\t開発者\n\t\t\t\t\t\t\t\tCookieに関する声明\n\t\t\t\t\t\t\t\tモバイルビュー\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\n\t\t\n(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgPageParseReport\":{\"limitreport\":{\"cputime\":\"0.280\",\"walltime\":\"0.372\",\"ppvisitednodes\":{\"value\":3631,\"limit\":1000000},\"ppgeneratednodes\":{\"value\":0,\"limit\":1500000},\"postexpandincludesize\":{\"value\":79499,\"limit\":2097152},\"templateargumentsize\":{\"value\":9174,\"limit\":2097152},\"expansiondepth\":{\"value\":26,\"limit\":40},\"expensivefunctioncount\":{\"value\":21,\"limit\":500},\"unstrip-depth\":{\"value\":0,\"limit\":20},\"unstrip-size\":{\"value\":1979,\"limit\":5000000},\"entityaccesscount\":{\"value\":1,\"limit\":400},\"timingprofile\":[\"100.00%  216.783      1 -total\",\" 40.69%   88.212      2 Template:Cite_journal\",\" 30.98%   67.158     21 Template:仮リンク\",\" 29.63%   64.243      2 Template:Citation/core\",\" 22.23%   48.184      1 Template:並列コンピューティング\",\" 21.76%   47.174     21 Template:仮リンク/link\",\" 20.35%   44.110      1 Template:Navbox\",\" 16.63%   36.052     21 Template:Wikipedia言語名\",\" 15.73%   34.109      1 Template:Commonscat\",\" 14.90%   32.297      1 Template:Sister\"]},\"scribunto\":{\"limitreport-timeusage\":{\"value\":\"0.024\",\"limit\":\"10.000\"},\"limitreport-memusage\":{\"value\":2221095,\"limit\":52428800}},\"cachereport\":{\"origin\":\"mw1338\",\"timestamp\":\"20181027040605\",\"ttl\":1900800,\"transientcontent\":false}}});mw.config.set({\"wgBackendResponseTime\":99,\"wgHostname\":\"mw1333\"});});\n\t\n\n"}